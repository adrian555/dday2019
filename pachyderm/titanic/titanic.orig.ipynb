{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create spark session connecting to standalone cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://master0.ddoc.os.fyre.ibm.com:31505\") \\\n",
    "    .appName(\"demo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import spark sql and ml for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv = pd.read_csv(\"http://oc-minio-default.apps.ddoc.os.fyre.ibm.com/titanic/train.orig.csv\", dtype=str)\n",
    "csv = csv.where((pd.notnull(csv)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "columns_struct_fields = [StructField(field_name, StringType(), True)\n",
    "                                 for field_name in csv.columns]\n",
    "schema = StructType(columns_struct_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(csv, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(col(\"Survived\").cast(\"int\"),col(\"PassengerId\").cast(\"int\"),col(\"Name\"),col(\"Parch\").cast(\"int\"),col(\"Sex\"),col(\"Embarked\"),col(\"Pclass\").cast(\"int\"),col(\"Age\").cast(\"double\"),col(\"SibSp\").cast(\"int\"),col(\"Fare\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+-----+------+--------+------+----+-----+-------+\n",
      "|Survived|PassengerId|                Name|Parch|   Sex|Embarked|Pclass| Age|SibSp|   Fare|\n",
      "+--------+-----------+--------------------+-----+------+--------+------+----+-----+-------+\n",
      "|       0|          1|Braund, Mr. Owen ...|    0|  male|       S|     3|22.0|    1|   7.25|\n",
      "|       1|          2|Cumings, Mrs. Joh...|    0|female|       C|     1|38.0|    1|71.2833|\n",
      "|       1|          3|Heikkinen, Miss. ...|    0|female|       S|     3|26.0|    0|  7.925|\n",
      "|       1|          4|Futrelle, Mrs. Ja...|    0|female|       S|     1|35.0|    1|   53.1|\n",
      "|       0|          5|Allen, Mr. Willia...|    0|  male|       S|     3|35.0|    0|   8.05|\n",
      "|       0|          6|    Moran, Mr. James|    0|  male|       Q|     3|null|    0| 8.4583|\n",
      "|       0|          7|McCarthy, Mr. Tim...|    0|  male|       S|     1|54.0|    0|51.8625|\n",
      "|       0|          8|Palsson, Master. ...|    1|  male|       S|     3| 2.0|    3| 21.075|\n",
      "|       1|          9|Johnson, Mrs. Osc...|    2|female|       S|     3|27.0|    0|11.1333|\n",
      "|       1|         10|Nasser, Mrs. Nich...|    0|female|       C|     2|14.0|    1|30.0708|\n",
      "|       1|         11|Sandstrom, Miss. ...|    1|female|       S|     3| 4.0|    1|   16.7|\n",
      "|       1|         12|Bonnell, Miss. El...|    0|female|       S|     1|58.0|    0|  26.55|\n",
      "|       0|         13|Saundercock, Mr. ...|    0|  male|       S|     3|20.0|    0|   8.05|\n",
      "|       0|         14|Andersson, Mr. An...|    5|  male|       S|     3|39.0|    1| 31.275|\n",
      "|       0|         15|Vestrom, Miss. Hu...|    0|female|       S|     3|14.0|    0| 7.8542|\n",
      "|       1|         16|Hewlett, Mrs. (Ma...|    0|female|       S|     2|55.0|    0|   16.0|\n",
      "|       0|         17|Rice, Master. Eugene|    1|  male|       Q|     3| 2.0|    4| 29.125|\n",
      "|       1|         18|Williams, Mr. Cha...|    0|  male|       S|     2|null|    0|   13.0|\n",
      "|       0|         19|Vander Planke, Mr...|    0|female|       S|     3|31.0|    1|   18.0|\n",
      "|       1|         20|Masselmani, Mrs. ...|    0|female|       C|     3|null|    0|  7.225|\n",
      "+--------+-----------+--------------------+-----+------+--------+------+----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|Pclass|Survived|count|\n",
      "+------+--------+-----+\n",
      "|     1|       0|   80|\n",
      "|     3|       1|  119|\n",
      "|     1|       1|  136|\n",
      "|     2|       1|   87|\n",
      "|     2|       0|   97|\n",
      "|     3|       0|  372|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Pclass\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handle rows with null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function use to print feature with null values and null count \n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function\n",
    "null_columns_count_list = null_value_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|              Embarked|                2|\n",
      "|                   Age|              177|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up Name for clue of age to be assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Initial|\n",
      "+--------+\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|    Capt|\n",
      "|     Mme|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Miss|\n",
      "|  Other|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ages = df.groupby('Initial').avg('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_age(x):\n",
    "    return round(mean_ages.filter(mean_ages.Initial == x).select('avg(Age)').collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now impute the age by initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Age\",when((df[\"Initial\"] == \"Miss\") & (df[\"Age\"].isNull()), get_mean_age('Miss')).otherwise(df[\"Age\"]))\n",
    "df = df.withColumn(\"Age\",when((df[\"Initial\"] == \"Other\") & (df[\"Age\"].isNull()), get_mean_age('Other')).otherwise(df[\"Age\"]))\n",
    "df = df.withColumn(\"Age\",when((df[\"Initial\"] == \"Master\") & (df[\"Age\"].isNull()), get_mean_age('Master')).otherwise(df[\"Age\"]))\n",
    "df = df.withColumn(\"Age\",when((df[\"Initial\"] == \"Mr\") & (df[\"Age\"].isNull()), get_mean_age('Mr')).otherwise(df[\"Age\"]))\n",
    "df = df.withColumn(\"Age\",when((df[\"Initial\"] == \"Mrs\") & (df[\"Age\"].isNull()), get_mean_age('Mrs')).otherwise(df[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked null value, impute with the majority value of 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create Family_size and Alone for more analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Family_Size|count|\n",
      "+-----------+-----+\n",
      "|          1|  161|\n",
      "|          6|   12|\n",
      "|          3|   29|\n",
      "|          5|   22|\n",
      "|          4|   15|\n",
      "|          7|    6|\n",
      "|         10|    7|\n",
      "|          2|  102|\n",
      "|          0|  537|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Family_Size\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Alone',lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Alone\",when(df[\"Family_Size\"] == 0, 1).otherwise(df[\"Alone\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert Sex, Embarked & Initial columns from string to number using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Initial: string (nullable = true)\n",
      " |-- Family_Size: integer (nullable = true)\n",
      " |-- Alone: integer (nullable = false)\n",
      " |-- Sex_index: double (nullable = false)\n",
      " |-- Embarked_index: double (nullable = false)\n",
      " |-- Initial_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop columns not for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"PassengerId\",\"Name\",\"Embarked\",\"Sex\",\"Initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Family_Size: integer (nullable = true)\n",
      " |-- Alone: integer (nullable = false)\n",
      " |-- Sex_index: double (nullable = false)\n",
      " |-- Embarked_index: double (nullable = false)\n",
      " |-- Initial_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|Survived|Parch|Pclass| Age|SibSp|   Fare|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|            features|\n",
      "+--------+-----+------+----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|       0|    0|     3|22.0|    1|   7.25|          1|    0|      0.0|           0.0|          0.0|(10,[1,2,3,4,5],[...|\n",
      "|       1|    0|     1|38.0|    1|71.2833|          1|    0|      1.0|           1.0|          2.0|[0.0,1.0,38.0,1.0...|\n",
      "|       1|    0|     3|26.0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|[0.0,3.0,26.0,0.0...|\n",
      "|       1|    0|     1|35.0|    1|   53.1|          1|    0|      1.0|           0.0|          2.0|[0.0,1.0,35.0,1.0...|\n",
      "|       0|    0|     3|35.0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[1,2,4,6],[3....|\n",
      "|       0|    0|     3|33.0|    0| 8.4583|          0|    1|      0.0|           2.0|          0.0|(10,[1,2,4,6,8],[...|\n",
      "|       0|    0|     1|54.0|    0|51.8625|          0|    1|      0.0|           0.0|          0.0|(10,[1,2,4,6],[1....|\n",
      "|       0|    1|     3| 2.0|    3| 21.075|          4|    0|      0.0|           0.0|          3.0|[1.0,3.0,2.0,3.0,...|\n",
      "|       1|    2|     3|27.0|    0|11.1333|          2|    0|      1.0|           0.0|          2.0|[2.0,3.0,27.0,0.0...|\n",
      "|       1|    0|     2|14.0|    1|30.0708|          1|    0|      1.0|           1.0|          2.0|[0.0,2.0,14.0,1.0...|\n",
      "|       1|    1|     3| 4.0|    1|   16.7|          2|    0|      1.0|           0.0|          1.0|[1.0,3.0,4.0,1.0,...|\n",
      "|       1|    0|     1|58.0|    0|  26.55|          0|    1|      1.0|           0.0|          1.0|[0.0,1.0,58.0,0.0...|\n",
      "|       0|    0|     3|20.0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[1,2,4,6],[3....|\n",
      "|       0|    5|     3|39.0|    1| 31.275|          6|    0|      0.0|           0.0|          0.0|[5.0,3.0,39.0,1.0...|\n",
      "|       0|    0|     3|14.0|    0| 7.8542|          0|    1|      1.0|           0.0|          1.0|[0.0,3.0,14.0,0.0...|\n",
      "|       1|    0|     2|55.0|    0|   16.0|          0|    1|      1.0|           0.0|          2.0|[0.0,2.0,55.0,0.0...|\n",
      "|       0|    1|     3| 2.0|    4| 29.125|          5|    0|      0.0|           2.0|          3.0|[1.0,3.0,2.0,4.0,...|\n",
      "|       1|    0|     2|33.0|    0|   13.0|          0|    1|      0.0|           0.0|          0.0|(10,[1,2,4,6],[2....|\n",
      "|       0|    0|     3|31.0|    1|   18.0|          1|    0|      1.0|           0.0|          2.0|[0.0,3.0,31.0,1.0...|\n",
      "|       1|    0|     3|36.0|    0|  7.225|          0|    1|      1.0|           1.0|          2.0|[0.0,3.0,36.0,0.0...|\n",
      "+--------+-----+------+----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into train and test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run training GBT (Gradient-boosted tree classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[0.0,1.0,28.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,3,4,5],[...|\n",
      "|       1.0|       0|[0.0,2.0,24.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|[0.0,2.0,29.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6,8],[...|\n",
      "|       1.0|       0|[0.0,2.0,38.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       1.0|       0|[0.0,3.0,18.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,6],[3.0,...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10, seed=20, maxDepth=4)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_prediction = gbt_model.transform(testData)\n",
    "gbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient-boosted tree classifie is = 0.819767\n",
      "Test Error of Gradient-boosted tree classifie 0.180233\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\n",
    "print(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|[0.0,1.0,28.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,3,4,5],[...|\n",
      "|       1.0|       0|[0.0,2.0,24.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|[0.0,2.0,29.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6,8],[...|\n",
      "|       1.0|       0|[0.0,2.0,38.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       1.0|       0|[0.0,3.0,18.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,6],[3.0,...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is = 0.790698\n",
      "Test Error of LogisticRegression = 0.209302 \n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run SVM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[0.0,1.0,28.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[1....|\n",
      "|       0.0|       0|(10,[1,2,3,4,5],[...|\n",
      "|       1.0|       0|[0.0,2.0,24.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[2....|\n",
      "|       0.0|       0|[0.0,2.0,29.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6,8],[...|\n",
      "|       1.0|       0|[0.0,2.0,38.0,0.0...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       1.0|       0|[0.0,3.0,18.0,1.0...|\n",
      "|       0.0|       0|(10,[1,2,6],[3.0,...|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "|       0.0|       0|(10,[1,2,4,6],[3....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "svm_model = svm.fit(trainingData)\n",
    "svm_prediction = svm_model.transform(testData)\n",
    "svm_prediction.select(\"prediction\", \"Survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine is = 0.80814\n",
      "Test Error of Support Vector Machine = 0.19186 \n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = evaluator.evaluate(svm_prediction)\n",
    "print(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\n",
    "print(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
